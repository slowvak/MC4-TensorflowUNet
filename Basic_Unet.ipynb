{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Basic_Unet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slowvak/MC4-TensorflowUNet/blob/master/Basic_Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCIBdsCviTkF",
        "colab_type": "text"
      },
      "source": [
        "Cell 1 loads up all the libraries we are using. In the first lessons, we used fastAI, while in this one we use Tensorflow with Keras. Both of these are large libraries, and its designers decided to allow programmers to load only the pieces that are relevant, which is what the 'from keras.XXX import YYY' lines do--they load just the partrt of Keras (or other library) that we want. This makes the load time faster and the final running program smaller.\n",
        "\n",
        "The second half of this cell does the familiar step of loading the data sets that I have prepared, which in this case are a series of abdominal CTs as well as hand-traced masks of the Pancreas, courtesy of The Cancer Image Archive: http://TheCancerImageArchive...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngjE5zA0F1PE",
        "colab_type": "code",
        "outputId": "9fb77bd0-49dc-492e-b9d1-51a10ef4d6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Cell 1\n",
        "# Load the {{PROCESSED}} images and the masks for pancreas from RSNA repository\n",
        "# To make load times reasonable, only slices with pancreas are included\n",
        "#  and these are 8 bit JPEG images (compresssed)\n",
        "\n",
        "!rm -rf ./MC4-TensorflowUNet\n",
        "\n",
        "!rm -rf images\n",
        "!mkdir images\n",
        "!rm -rf masks\n",
        "!mkdir masks\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "!git clone https://github.com/slowvak/MC4-TensorflowUNet.git\n",
        "\n",
        "\n",
        "#for f in os.listdir('./MC4-TensorflowUNet'):\n",
        "#    cmd = 'unzip ./MC4-TensorflowUNet/{}'.format(f)\n",
        "#    os.system(cmd)\n",
        "#    limit = limit - 1\n",
        "#    if limit < 0:\n",
        "#        break\n",
        "\n",
        "!unzip -q -o ./MC4-TensorflowUNet/Pt1.zip\n",
        "!unzip -q -o ./MC4-TensorflowUNet/Pt2.zip\n",
        "!unzip -q -o ./MC4-TensorflowUNet/Pt3.zip\n",
        "\n",
        "!mv *-Mask.jpg ./masks\n",
        "!mv *.jpg ./images\n",
        "\n",
        "#!ls images\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MC4-TensorflowUNet'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 109 (delta 7), reused 0 (delta 0), pack-reused 85\u001b[K\n",
            "Receiving objects: 100% (109/109), 371.49 MiB | 29.59 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Checking out files: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg-8caamcSTp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Q29ksprFz2",
        "colab_type": "code",
        "outputId": "0570b7e7-d2f8-44bd-d604-e193dbb25289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q keras\n",
        "import keras\n",
        "from __future__ import print_function\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.layers.core import Lambda\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "import numpy\n",
        "import matplotlib as plt\n",
        "#import matplotlib.image as mpimg\n",
        "import imageio\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiNnuEKhkS0t",
        "colab_type": "code",
        "outputId": "da37317e-a34a-4daf-dada-7dae7155a0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get training and testing data\n",
        "# This Block loads the training images and training masks into numpy arrays of shape (n, 256, 256)\n",
        "\n",
        "\n",
        "train_X = []\n",
        "train_Y = []\n",
        "test_X = []\n",
        "test_Y = []\n",
        "\n",
        "\n",
        "limit = 3500  # limit number of subjects due to memory limits\n",
        "test_num = 250  # will also load some test images for the end\n",
        "\n",
        "im_list = os.listdir('./images')\n",
        "\n",
        "for f in im_list:\n",
        "  pth = './images/' + f \n",
        "  img = imageio.imread(pth)\n",
        "  if len(train_X) >= limit:\n",
        "    test_X.append(np.array(img))\n",
        "  else:\n",
        "    train_X.append(np.array(img))\n",
        "  if len(test_X) >= test_num:\n",
        "    break\n",
        "\n",
        "im_list = os.listdir('./masks')\n",
        "for f in im_list:\n",
        "  pth = './masks/' + f \n",
        "  img = imageio.imread(pth)\n",
        "  if len(train_Y) >= limit:\n",
        "    test_Y.append(np.array(img))\n",
        "  else:\n",
        "    train_Y.append(np.array(img))\n",
        "  if len(test_Y) >= test_num:\n",
        "    break\n",
        "\n",
        "X_array = numpy.array(train_X)\n",
        "Y_array = numpy.array(train_Y)  \n",
        "# the 2 lines below adds an axis, which is needed by Keras\n",
        "X_array = X_array[..., np.newaxis]\n",
        "Y_array = Y_array[..., np.newaxis]\n",
        "\n",
        "X_test = numpy.array(test_X)\n",
        "Y_test = numpy.array(test_Y)                                            \n",
        "X_test = X_test[..., np.newaxis]\n",
        "Y_test = Y_test[..., np.newaxis]\n",
        "\n",
        "X_array.shape\n",
        "CHANNELS = X_array.shape[3]\n",
        "IMG_WIDTH = X_array.shape[2]\n",
        "IMG_HEIGHT = X_array.shape[1]\n",
        "NUM_IMAGES = X_array.shape[0]\n",
        "K.set_image_dim_ordering('tf')\n",
        "\n",
        "print (str(NUM_IMAGES) + ' for training and validation, and testing has ' + str(X_test.shape[0]))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3500 for training and validation, and testing has 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1PV_Zmthf7Y",
        "colab_type": "text"
      },
      "source": [
        "# Cost Functions\n",
        "A critical element of every machine learning algorithm is to select a good cost function. In the classificaiton problems of prior articles, we used the accuracy of predictions as the cost function. For segmentation, one potentially could compute a score for teh classification of each pixel (object or not object), but a more common metric is the Dice Similiarity Score (a.k.a. Dice Score). This essentially means the amount of overlap between the gold standard and the prediction. If they perfectly agree, the Dice Score is 1, and if there is no overlap, the score is 0. We can convert the Dice Score toa Dice Loss by subtracting it from 1. One can also convert the Dice Score to a cross-entropy function, and this can work well in some cases. Code for both is provided, and you are encouraged to try both cost functions to see the effect.\n",
        "Note, however, that the above can result in Dice values of zero, and we don't want to divide by zero. In fact, we don't want to divide by a small number, so we add 'smooth' to the value (in our case we are using 1) so the values of Dice actually are 1 to 2, not 0 to 1. And that means the Dice Loss will be -1 to 0, but the loss reported is the sum, so it will have a larger range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtR4fbhhhegw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell \n",
        "tf.reset_default_graph()\n",
        "\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 0.000001\n",
        "    # Flatten\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    if y_true_f + y_pred_f == 0:\n",
        "        return 4 * smooth\n",
        "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "#binary cross entropy is another function that can perform well\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4NU5_ehlK5",
        "colab_type": "text"
      },
      "source": [
        "##Building the U-Net\n",
        "We are finally ready to build our Network. One difference of Keras versus the previous examples of FastAI is that Keras is designed so that there is one line of code for each layer of the network (plus the setup and training/evlauation code).  This means that for a moderately complex network like a ResNet34 classifier, there would be 34 lines of code. \n",
        "U-Nets are popular network architectures for segmentation. These get their name because of the unique way they are built: The first part produces repeated reductions in resolution as the 'important' parts of the image are retained that reflect the structures that it is trained to recognize. Typically there are 4 or 5 such reduction layers that each consist of convultions, ReLUs, and Pooling layers. \n",
        "Once the image is reduced to the critical components, the networks begins to reconstruct the precise margins of the critical elements by using 'skip layers'. As the resolution is stored using convolutional-transpose layers, the layers 'look' back to the layers where the resolution was reduced to try to best define the margins of the structures.\n",
        "See Ronneberger..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-AbL6fvgPWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell \n",
        "\n",
        "\n",
        "# Build U-Net model\n",
        "def build_model(drop_out = 0.0, act_fn = 'relu', init_fn = 'he_normal'):\n",
        "\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
        "    s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "    c1 = Conv2D(32, (7, 7), activation=act_fn, kernel_initializer=init_fn, padding='same') (s)\n",
        "    #c1 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (s)\n",
        "    if drop_out > 0.0:\n",
        "        c1 = Dropout(drop_out) (c1)\n",
        "        c1 = Conv2D(32, (7, 7), activation=act_fn, kernel_initializer=init_fn, padding='same') (c1)\n",
        "    p1 = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p1)\n",
        "    if drop_out > 0.0:\n",
        "        c2 = Dropout(drop_out) (c2)\n",
        "        c2 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p2)\n",
        "    if drop_out > 0.0:\n",
        "        c3 = Dropout(drop_out) (c3)\n",
        "        c3 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p3)\n",
        "    if drop_out > 0.0:\n",
        "        c4 = Dropout(drop_out) (c4)\n",
        "        c4 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p4)\n",
        "    if drop_out > 0.0:\n",
        "        c5 = Dropout(drop_out) (c5)\n",
        "        c5 = Conv2D(256, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u6)\n",
        "    if drop_out > 0.0:\n",
        "        c6 = Dropout(drop_out) (c6)\n",
        "        c6 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u7)\n",
        "    if drop_out > 0.0:\n",
        "        c7 = Dropout(drop_out) (c7)\n",
        "        c7 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u8)\n",
        "    if drop_out > 0.0:\n",
        "        c8 = Dropout(drop_out) (c8)\n",
        "        c8 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u9)\n",
        "    if drop_out > 0.0:\n",
        "        c9 = Dropout(drop_out) (c9)\n",
        "        c9 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    #model.compile(optimizer='adam'(lr=0.0001,decay=0.000001), loss='dice_loss', metrics=[dice_coeff])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coeff])\n",
        "#    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Build U-Net model\n",
        "def build_shallow_model(drop_out = 0.0, act_fn = 'relu', init_fn = 'he_normal'):\n",
        "\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
        "    s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "    c1 = Conv2D(32, (7, 7), activation=act_fn, kernel_initializer=init_fn, padding='same') (s)\n",
        "    #c1 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (s)\n",
        "    if drop_out > 0.0:\n",
        "        c1 = Dropout(drop_out) (c1)\n",
        "        c1 = Conv2D(32, (7, 7), activation=act_fn, kernel_initializer=init_fn, padding='same') (c1)\n",
        "    p1 = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p1)\n",
        "    if drop_out > 0.0:\n",
        "        c2 = Dropout(drop_out) (c2)\n",
        "        c2 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p2)\n",
        "    if drop_out > 0.0:\n",
        "        c3 = Dropout(drop_out) (c3)\n",
        "        c3 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "    \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c3)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u8)\n",
        "    if drop_out > 0.0:\n",
        "        c8 = Dropout(drop_out) (c8)\n",
        "        c8 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u9)\n",
        "    if drop_out > 0.0:\n",
        "        c9 = Dropout(drop_out) (c9)\n",
        "        c9 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    #model.compile(optimizer='adam'(lr=0.0001,decay=0.000001), loss='dice_loss', metrics=[dice_coeff])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coeff])\n",
        "#    model.summary()\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2cXNLhBqGat",
        "colab_type": "code",
        "outputId": "ba4e4a4e-cfaf-4ce5-8fad-56822fb57b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "tb = TensorBoardColab()\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://95415872.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbJTd6AVlFkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpON3sHvl_7x",
        "colab_type": "text"
      },
      "source": [
        "# Train it\n",
        "Now that our model is built, we are (finally!) ready to train it. Trial and error with colab hardware (K80) has shown that a batch_size of 16 works, and that we can get reasonable results adfter 5 epochs (but you can train longer to get better results)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMOBlqyRmA4w",
        "colab_type": "code",
        "outputId": "4728052e-f288-4089-9b99-8fff3ccbbf4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "epochs = 50\n",
        "# more than 50 produces overfitting--train performance keeps incrasing while validation performance starts dropping--try 100 epochs\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "# code to use tensorboard\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -fq ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# start the tensorboard app\n",
        "!mkdir ./log\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "# see results on port 6006\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# then make access available to your computer\n",
        "# this will create an URL for you to click on to see the training\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "        \n",
        "# Also need to make a callback--a way to have the training routine post its results to Tensorboard\n",
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "#Must add \"callbacks=[tbCallBack]\" (without the quotes) to the model.fit call\n",
        "\n",
        "\n",
        "# Fit model\n",
        "checkpointer = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "#for dropout in [0.0, 0.2, 0.5]:\n",
        "for dropout in [0.0]:\n",
        "    print ('\\n\\nDropout = ' + str(dropout))\n",
        "    model = build_shallow_model(drop_out = dropout)\n",
        "    # adding dropout takes 2x time, so allow for twice as many epochs to get about equal execution time\n",
        "    if dropout < 0.05:\n",
        "        epoch_cnt = epochs * 2\n",
        "    else:\n",
        "        epoch_cnt = epochs\n",
        "    results = model.fit(X_array, Y_array, validation_split=0.2, batch_size=batch_size, epochs=epoch_cnt, callbacks=[tbCallBack])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-23 17:30:48--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.232.40.183, 52.201.75.180, 52.207.111.186, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.232.40.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13607069 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  12.98M  14.5MB/s    in 0.9s    \n",
            "\n",
            "2019-08-23 17:30:49 (14.5 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13607069/13607069]\n",
            "\n",
            "https://95415872.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0823 17:30:55.009787 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0823 17:30:55.016321 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0823 17:30:55.028056 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0823 17:30:55.057971 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0823 17:30:55.089307 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Dropout = 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0823 17:30:55.313208 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0823 17:30:55.337427 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0823 17:30:55.343024 140188106078080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2800 samples, validate on 700 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0823 17:30:59.169125 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:848: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0823 17:30:59.394568 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:840: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0823 17:31:02.609343 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0823 17:31:02.612603 140188106078080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2800/2800 [==============================] - 39s 14ms/step - loss: 0.5230 - dice_coeff: 0.5733 - val_loss: 0.3212 - val_dice_coeff: 0.6475\n",
            "Epoch 2/100\n",
            "2800/2800 [==============================] - 29s 10ms/step - loss: 0.3218 - dice_coeff: 0.7469 - val_loss: 0.3329 - val_dice_coeff: 0.6901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-65cc3805e2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mepoch_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    939\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                     \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVgGQWCSoQbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FastAI version of UNet\n",
        "from fastai.vision import *\n",
        "\n",
        "\n",
        "\n",
        "# first, prepare the DataBunch\n",
        "path_msk = './masks/'\n",
        "path_img = './images/'\n",
        "\n",
        "def listdir_fullpath(d):\n",
        "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
        "\n",
        "fnames = listdir_fullpath(path_img)\n",
        "lbl_names = listdir_fullpath(path_msk)\n",
        "\n",
        "codes = ['NotTumor', 'Tumor']\n",
        "\n",
        "# open and show image\n",
        "img_f = fnames[10]\n",
        "img = open_image(img_f)\n",
        "img.show(figsize=(5, 5))\n",
        "\n",
        "get_mask_file_fn = lambda x: os.path.join(path_msk,os.path.basename(x).replace ('.jpg', '-Mask.jpg'))\n",
        "\n",
        "size = 400\n",
        "batch_size = 32\n",
        "\n",
        "src = (SegmentationItemList.from_folder(path_img)\n",
        "       # Load in x data from folder\n",
        "       .split_by_rand_pct(valid_pct = 0.2, seed=None)\n",
        "       .label_from_func(get_mask_file_fn, classes=codes)\n",
        "       # Label data using the get_y_fn function\n",
        ")\n",
        "\n",
        "data = (src.transform(get_transforms(), size=size, tfm_y=True)\n",
        "        # Flip images horizontally \n",
        "        .databunch(bs=batch_size)\n",
        "        #.normalize(imagenet_stats)\n",
        "        # Normalize for resnet\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lf6_8e3o9N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "learn = unet_learner(data, models.resnet18, metrics=dice, wd=1e-2)\n",
        "\n",
        "\n",
        "learn.lr_find() # find learning rate\n",
        "learn.recorder.plot() # plot learning rate graph\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSr1bkl-oZ9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 3e-3 # pick a lr\n",
        "learn.fit_one_cycle(10, slice(lr), pct_start=0.9) # train model\n",
        "\n",
        "learn.save('LGG') # save model\n",
        "learn.show_results(rows=3, figsize=(8, 9)) # show results\n",
        "\n",
        "\n",
        "learn.unfreeze() # unfreeze all layers\n",
        "\n",
        "# find and plot lr again\n",
        "learn.unfreeze()\n",
        "learn.recorder.plot()\n",
        "\n",
        "# train model \n",
        "learn.fit_one_cycle(12, slice(lr/400, lr/4), pct_start=0.8)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPD1HnHtieRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55b00d06-8c7f-4b65-b3ef-05f444056eb8"
      },
      "source": [
        "# from https://github.com/hlamba28/UNET-TGS/blob/master/TGS%20UNET.ipynb\n",
        "\n",
        "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    # first layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # second layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
        "    \"\"\"Function to define the UNET Model\"\"\"\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "    \n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "    \n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "    \n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    # Expansive Path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "input_img = Input((IMG_HEIGHT, IMG_WIDTH, CHANNELS), name='img')\n",
        "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]\n",
        "\n",
        "results = model.fit(X_array, Y_array, validation_split=0.2, batch_size=batch_size, epochs=epoch_cnt, callbacks=callbacks)\n",
        "#results = model.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=callbacks,\\\n",
        "#                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2800 samples, validate on 700 samples\n",
            "Epoch 1/100\n",
            "2800/2800 [==============================] - 65s 23ms/step - loss: 0.2532 - acc: 0.6581 - val_loss: -0.0260 - val_acc: 0.6476\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to -0.02603, saving model to model.h5\n",
            "Epoch 2/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -0.0376 - acc: 0.6974 - val_loss: -0.6554 - val_acc: 0.6434\n",
            "\n",
            "Epoch 00002: val_loss improved from -0.02603 to -0.65538, saving model to model.h5\n",
            "Epoch 3/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -0.1335 - acc: 0.7035 - val_loss: -0.7283 - val_acc: 0.7547\n",
            "\n",
            "Epoch 00003: val_loss improved from -0.65538 to -0.72835, saving model to model.h5\n",
            "Epoch 4/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -0.3893 - acc: 0.7338 - val_loss: 1.0026 - val_acc: 0.5293\n",
            "\n",
            "Epoch 00004: val_loss did not improve from -0.72835\n",
            "Epoch 5/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -0.5529 - acc: 0.6952 - val_loss: -0.8353 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00005: val_loss improved from -0.72835 to -0.83534, saving model to model.h5\n",
            "Epoch 6/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -0.7039 - acc: 0.7036 - val_loss: -0.7818 - val_acc: 0.7169\n",
            "\n",
            "Epoch 00006: val_loss did not improve from -0.83534\n",
            "Epoch 7/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -0.7912 - acc: 0.7115 - val_loss: -0.1792 - val_acc: 0.7645\n",
            "\n",
            "Epoch 00007: val_loss did not improve from -0.83534\n",
            "Epoch 8/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -1.0062 - acc: 0.7170 - val_loss: -0.6383 - val_acc: 0.6947\n",
            "\n",
            "Epoch 00008: val_loss did not improve from -0.83534\n",
            "Epoch 9/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -1.2891 - acc: 0.7400 - val_loss: 0.2748 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00009: val_loss did not improve from -0.83534\n",
            "Epoch 10/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -1.4558 - acc: 0.7984 - val_loss: -1.0934 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00010: val_loss improved from -0.83534 to -1.09335, saving model to model.h5\n",
            "Epoch 11/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -1.5811 - acc: 0.7955 - val_loss: -1.0456 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00011: val_loss did not improve from -1.09335\n",
            "Epoch 12/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -1.7936 - acc: 0.8281 - val_loss: -1.1468 - val_acc: 0.7559\n",
            "\n",
            "Epoch 00012: val_loss improved from -1.09335 to -1.14675, saving model to model.h5\n",
            "Epoch 13/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -1.7758 - acc: 0.8065 - val_loss: -1.4780 - val_acc: 0.7335\n",
            "\n",
            "Epoch 00013: val_loss improved from -1.14675 to -1.47803, saving model to model.h5\n",
            "Epoch 14/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -2.0835 - acc: 0.8295 - val_loss: -1.2599 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00014: val_loss did not improve from -1.47803\n",
            "Epoch 15/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -2.1931 - acc: 0.8096 - val_loss: 0.4898 - val_acc: 0.9757\n",
            "\n",
            "Epoch 00015: val_loss did not improve from -1.47803\n",
            "Epoch 16/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -2.3401 - acc: 0.8288 - val_loss: -0.7582 - val_acc: 0.6722\n",
            "\n",
            "Epoch 00016: val_loss did not improve from -1.47803\n",
            "Epoch 17/100\n",
            "2800/2800 [==============================] - 50s 18ms/step - loss: -2.4144 - acc: 0.8287 - val_loss: -1.5401 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00017: val_loss improved from -1.47803 to -1.54011, saving model to model.h5\n",
            "Epoch 18/100\n",
            "1984/2800 [====================>.........] - ETA: 13s - loss: -2.3304 - acc: 0.8205"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a8bbf2e7ae63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m ]\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;31m#results = model.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=callbacks,\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#                    validation_data=(X_valid, y_valid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecCUengEkrEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_lb5lCQmZSB",
        "colab_type": "text"
      },
      "source": [
        "# Test it!\n",
        "Now that the model is trained, we can test our segmentation tool on the test holdout cases. Note that the prediction is the probability that a pixel is object (pancreas) or not object (anything other than pancreas). We use 0.5 as the threshold for deciding Pancreas or not, though again you can adjust this if your task might view it as more valuable to include non-pancreas pixels in order to reduce the number of missed pancreas pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV6XJMaLmeA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict on train, val and test\n",
        "#model = load_model('model.h5', custom_objects={'dice_loss': dice_loss, 'dice_coeff': dice_coeff})\n",
        "\n",
        "#preds_train = model.predict(X_array[:int(X_array.shape[0]*0.9)], verbose=1)\n",
        "#preds_val = model.predict(X_array[int(X_test.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "#preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "#preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Create list of upsampled test masks\n",
        "#preds_test_upsampled = []\n",
        "#for i in range(len(preds_test)):\n",
        "#    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True))\n",
        "\n",
        "fig, axs = plt.subplots(1, 9, figsize=(21, 3))\n",
        "axs[0].imshow(np.squeeze(X_test[0]), cmap=cm.gray)\n",
        "axs[1].imshow(np.squeeze(Y_test[0]))\n",
        "axs[2].imshow(np.squeeze(preds_test_t[0]))\n",
        "axs[3].imshow(np.squeeze(X_test[4]), cmap=cm.gray)\n",
        "axs[4].imshow(np.squeeze(Y_test[4]))\n",
        "axs[5].imshow(np.squeeze(preds_test_t[4]))\n",
        "axs[6].imshow(np.squeeze(X_test[9]), cmap=cm.gray)\n",
        "axs[7].imshow(np.squeeze(Y_test[9]))\n",
        "axs[8].imshow(np.squeeze(preds_test_t[9]))\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}